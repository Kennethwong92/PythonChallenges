from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
myurl = "https://dailyclack.com/collections/group-buys"
urlclient = urlopen(myurl) #open webpage and takes the html
page_html = urlclient.read()
urlclient.close()
page_soup = soup(page_html, "html.parser") #parsers the html
items = page_soup.findAll("div",{"class":"product-card__name"}) #grabs every product on that page
print(len(items))
out_filename = "Dailyclack.csv" #csv file name
headers = "product name\n"
f = open(out_filename, "w")
f.write(headers)
for item in items:
    product_name = item.text
    f.write(product_name.replace(",","|") + "," + "\n")
f.close()


